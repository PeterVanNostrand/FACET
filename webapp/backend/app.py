import numpy as np
from flask import Flask, request, jsonify
from flask_cors import CORS
import json
from webapp.app_utilities import run_facet, parse_dataset_info
from dataset import get_json_paths, DataInfo
from pprint import pprint

# load app confiuration parameters
with open("./webapp/config.json", "r") as config_file:
    APP_CONFIG: dict = json.load(config_file)  # config file with app parameters
API_PORT: int = APP_CONFIG["API_PORT"]  # specified port for RESTful explanation API
DS_NAME: str = APP_CONFIG["DATASET"]  # the dataset we're explaining
DETAILS_PATH, HUMAN_PATH = get_json_paths(
    DS_NAME
)  # the paths to the ds_details, and human_readible info
DS_INFO: DataInfo = None
HUMAN_FORMAT: dict = None

# configure the app
app = Flask(__name__)
CORS(app)
FACET_CORE = None  # the core facet system which generated explanations
SAMPLE_DATA: np.ndarray = None  # teh set of sample instances we populate for the demo


def init_app():
    global FACET_CORE, SAMPLE_DATA, DS_INFO, HUMAN_FORMAT, DATA_FORMAT, FORMAT_DICT

    print("\nApp initializing...")
    # try:
    # initialize FACET (load data, train model, index explanations) and get samples
    FACET_CORE, SAMPLE_DATA = run_facet(ds_name=DS_NAME)
    # load the dataset info JSON file which is automatically generated by FACET
    DS_INFO = parse_dataset_info(DETAILS_PATH)

    # load the human readable JSON file used for display formatting
    with open(HUMAN_PATH, "r") as human_format_file:
        HUMAN_FORMAT = json.load(human_format_file)

    # load the dataset details JSON file used for display formatting
    with open(DETAILS_PATH, "r") as data_details_file:
        DATA_FORMAT = json.load(data_details_file)

    # append a mapping to FACET's col_ids x0, x1, ... , xN (from DS_INFO)
    HUMAN_FORMAT["feature_names"] = DS_INFO.col_names
    FORMAT_DICT = {}
    FORMAT_DICT.update(HUMAN_FORMAT)
    FORMAT_DICT.update(DATA_FORMAT)
    print("FORMAT_DICT")
    pprint(FORMAT_DICT)
    # except Exception as e:
    #     print(f"ERROR in init_app(): Failed to run FACET. Details:\n{e}")
    #     exit(1)
    print("App initialized\n")


init_app()


@app.route("/facet/instances", methods=["GET"])
def get_test_instances():
    num_arrays, array_length = SAMPLE_DATA.shape
    json_data = []

    # Iterate over the arrays and build the dictionary
    samples = DS_INFO.unscale(SAMPLE_DATA)  # undo normalization
    # samples = DS_INFO.unscale_points(SAMPLE_DATA)
    for instance in samples:
        instance_dict = DS_INFO.point_to_dict(instance)
        json_data.append(instance_dict)

    return jsonify(json_data)


@app.route("/facet/data_format", methods=["GET"])
def get_data_format():
    return jsonify(FORMAT_DICT)


@app.route("/facet/predict", methods=["POST"])
def predict_instance():
    data = request.json
    # fetch the instance
    instance = DS_INFO.dict_to_point(data["instance"])
    instance = DS_INFO.scale_points(instance)
    prediction = int(FACET_CORE.predict([instance])[0])
    return jsonify(prediction)


@app.route("/facet/explanations", methods=["POST"])
def facet_explanation():
    """
    This is the main API endpoint for explaining instances. It expects a request JSON object containing the following entries

    Parameters
    ----------
    `instance`: a dictionary with the instance values like {x0: value, ..., xn: value}
    `weights`: a dictionary with the weights values like {x0: weight, ..., xn: weight}
    `k`: an integer for the number of explantions to generate
    `constraints`: a dictionary with the constaints values like {x0: [lower, upper], ..., xn: [lower, upper]}

    Returns
    -------
    `regions: an array of regions dictionaries`
    """

    # try:
    data: dict = request.json
    # fetch the instance
    instance = DS_INFO.dict_to_point(data["instance"])
    # normalize the instance, e.g., $100 --> 0.1
    instance = DS_INFO.scale_points(instance)
    # fetch the weights
    weights = DS_INFO.dict_to_point(data["weights"])
    weights = np.nan_to_num(weights, nan=1.0)
    weights[weights == 0] = 1.0  # zero is invalid weight
    # fetch the constraints, normalize them as well
    constraints = np.array(data.get("constraints", None)).astype(float)
    constraints = DS_INFO.rescale_rects(constraints, scale_down=True)[0]
    num_explanations = data.get("num_explanations", 1)

    pprint(data)

    # Perform explanation using FACET explain
    prediction = FACET_CORE.predict(instance)
    points, regions = FACET_CORE.explain(
        x=instance,
        y=prediction,
        k=2 * num_explanations,
        constraints=constraints,
        weights=weights,
        return_regions=True,
    )

    # FACET generates a lot of duplicate regions, so we get the first k unique regions
    sorted_unique, un_idxs = np.unique(regions, return_index=True, axis=0)  # numpy sorts results by default
    unique_regions = regions[np.sort(un_idxs)]  # unsort the regions to preserve order by distance to x

    # unscale the regions back to semantic ranges (e.g., 0.1 -> $100) and dict-ify they for JS
    unscaled_regions = DS_INFO.rescale_rects(unique_regions, scale_down=False)
    region_dicts = [DS_INFO.rect_to_dict(_) for _ in unscaled_regions]

    return jsonify(region_dicts)

    # except Exception as e:
    #     print(e)
    #     return "\nError in facet_explanation(): " + str(e), 500


if __name__ == "__main__":
    app.run(port=API_PORT, debug=True)
