from detector import Detector
from sklearn.ensemble import RandomForestClassifier as skRandomForestClassifier
from sklearn import tree
import numpy as np
from utilities.tree_tools import TreeContraster
from utilities.metrics import euclidean_distance


class RandomForest(Detector):
    def __init__(self, hyperparameters=None):
        self.model = skRandomForestClassifier()

    def train(self, x, y=None):
        self.model.fit(x, y)

    def predict(self, x):
        return self.model.predict(x)

    def get_candidate_examples(self, x, y, difference=0.01, distance_metric="Euclidean"):
        trees = self.model.estimators_
        all_examples = []  # a list to store the array of examples returned by each tree

        # fore each tree, get an example for each sample in x
        for t in trees:
            helper = TreeContraster(t)
            tree_examples = helper.construct_examples(x, y, difference, distance_metric)
            all_examples.append(tree_examples)

        # get dimensions for the data
        nsamples = x.shape[0]
        nfeatures = x.shape[1]
        ntrees = self.model.n_estimators

        # convert list of arrays into a single array, shape = [ntrees, nsamples, nfeatures]
        # array contains an example for each instance in x generated by each tree
        forest_examples = np.array(all_examples)

        # compute the distance between each example and it corresponding instance in x
        ex_dists = euclidean_distance(x, forest_examples)

        # predict all the examples, to do this we temporarily flatten the examples array to 2D
        ex_preds = self.predict(forest_examples.reshape(ntrees*nsamples, nfeatures)).reshape((ntrees, nsamples))

        # swap axes so array now has shape = [nsamples, ntrees, nfeatures]
        # forest_examples[i] is a vector of candidate examples for x[i], one per tree
        forest_examples = np.swapaxes(forest_examples, 0, 1)
        ex_preds = np.swapaxes(ex_preds, 0, 1)
        ex_dists = np.swapaxes(ex_dists, 0, 1)

        # broadcast y to an array of shape [nsamples, ntrees] for comparison
        y_trees = np.array([y] * 100).swapaxes(0, 1)
        # find the cases where an example does not result in a change of class in prediction of the forest
        idx_unchanged = np.where(ex_preds == y_trees)
        # and set the distances for those cases to infinity
        ex_dists[idx_unchanged] = np.inf

        # find the index of the most similar example for each instance in x
        idx_best_ex = np.argmin(ex_dists, axis=1)

        # select the best example for each instance in x as an example which results in the prediction of the forest
        # changing classes and has a minimal distance

        final_examples = np.empty(shape=(nsamples, nfeatures))
        for i in range(nsamples):
            # if the distance is infinity, the prediction didn't change, return all nulls
            if ex_dists[i][idx_best_ex[i]] == np.inf:
                final_examples[i] = np.array([np.nan] * nfeatures)
            # if the distance is real, the prediction changed, use the corresponding candidate as the final example
            else:
                final_examples[i] = forest_examples[i][idx_best_ex[i]]

        return final_examples
